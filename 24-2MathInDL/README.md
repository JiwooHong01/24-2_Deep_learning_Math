# Introduction to Mathematics in Deep Learning

Class Materials:
Covering Probatility, Information Theory, Estimation Theory, Linear Algebra, Optimization



Chapter 1. Probability Review & Information Theory
- Definition of sample space/event/random variable
- Definition of Surprisal, Entropy(Entropy, Cross Entropy, Joint Entropy, Differential Entropy), Convexivity(Concavity), Mismatch, KL-Divergence
- Gaussian Distribution

Chapter 2. Estimation Theory
- Markov/Chebyshev/Fano's Inequalities
- Moment Generating Function
- Conditional Expectation
- MLE vs MAP
- Naive Bayes, Gaussian Descriminant
- positive (semi)definite matrix
- Bias vs Variance

Chapter 3. Optimization
- Linear Algebra(Norm, Orthogonal, SVM, Pseudo-inverse, Soft Prediction, Loss Function, Risks(Expected, Bayes, Empirical))
- L-Lipschitz, L-smooth, mu-strongly convex, co-coercivity, PL
- Gradient Descent
- Operator
- Nesterov's accelerated gradient method(AGM)
- Momentum, Nesterov oscillation
- SGD, Regularization, RMSProp, Adam, SAM

done. Mar 27, 2025
